{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1. Overview](#1)\n",
    "- [2. Function](#2)\n",
    "- [3. Training](#3)\n",
    "    - [3.1 Load Data Train](#31)\n",
    "    - [3.2 Train Model](#32)\n",
    "- [4. Predict Data Test](#4)\n",
    "    - [4.1 Create Data Test](#41)\n",
    "    - [4.2 Predict Probability](#42)\n",
    "    - [4.3 Predict Label with Probability Cut Off](#43)\n",
    "- [5. Save Results](#5)\n",
    "    - [5.1 Into Dataframe](#51)\n",
    "    - [5.2 Into csv file](#52)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "\n",
    "# 1. Overview\n",
    "Feature used in this model are inspired by [Grab](https://help.grab.com/driver/en-my/360001944868-Weekly-Safety-Report) and [Insurance Telematics paper by Peter Handel et. al](https://ieeexplore.ieee.org/document/6936433/authors#authors) as described below.\n",
    "\n",
    "| Peter Handel et. al Feature | Description                                                         | Weekly Safety Report Grab | Available Variable   |\n",
    "|---------------------|---------------------------------------------------------------------|--------------|----------------------|\n",
    "| Acceleration        | Number of rapid acceleration events and their harshness             | ✔            | Speed + Time, Gyro         |\n",
    "| Braking             | Number of harsh braking events and their harshness                  | ✔            | Speed + Time, Gyro         |\n",
    "| Speeding            | Amount of absolute speeding                                         | _              | Speed                |\n",
    "| Smoothness          | Long-term speed variations around a nominal speed                   | _              | Speed                |\n",
    "| Swerving            | Number of abrupt steering maneuvers and their harshness             |_             | Gyro + Acceleration  |\n",
    "| Cornering           | Number of events when turning at too high speed and their harshness | ✔            | Bearing + Gyro+ Time |\n",
    "| Elapsed time        | Time duration of the trip                                           |_              | Time                 |\n",
    "  \n",
    "Grab Telematics data consist of bookingID, Accuracy, Bearing, acceleration, gyro, second, and Speed. \n",
    "16 Million data point of telematics data transformed into 1 data point for each bookingID (transformed into total 20000 data point).\n",
    "\n",
    "\n",
    "| Original Feature              | Feature Aggregation per bookingID                                | Description                          |\n",
    "|----------------------|------------------------------------------------------------------|--------------------------------------|\n",
    "| second               | ```max_second```                                                       | `Elapsed Time`                                |\n",
    "| Speed                | ```mean_Speed```<br/>```median_Speed```<br/>```max_Speed```<br/>```std_Speed```<br/>```speed_diff``` | ```speed_diff``` is average of speed difference over time to estimate ```Smoothness``` along with `std_Speed`.<br/>```max_Speed```, `mean_Speed`, `median_Speed` estimate ```Speeding```.                      |\n",
    "| ```acceleration_(x,y,z)``` | ```mean_acceleration_(x,y,z)```<br/>```median_acceleration_(x,y,z)```<br/>```max_acceleration_(x,y,z)```<br/>```min_acceleration_(x,y,z)```<br/>```std_acceleration_(x,y,z)```<br/>```count(1,2,3)_acceleration_(x,y,z)```                                                  | ```count(1,2,3)_acceleration_(x,y,z)``` is how many times ```acceleration_(x,y,z)``` data goes to far from its median as described in advanced.pdf. Used to estimate harsh `Acceleration` and `Braking`.<br/><br/>Harsh Acceleration and Braking will result in medium(count2) to high(count3) acceleration_z value alteration                           |\n",
    "| gyro_(x,y,z)         | ```mean_gyro_(x,y,z)```<br/>```median_gyro_(x,y,z)```<br/>```max_gyro_(x,y,z)```<br/>```min_gyro_(x,y,z)```<br/>```std_gyro_(x,y,z)```<br/>```count(1,2,3)_gyro_(x,y,z)```                              | ```count(1,2,3)_gyro_(x,y,z)``` is how many times ```gyro_(x,y,z)``` data goes to far from its median as described in advanced.pdf. Used to estimate harsh `Acceleration`, `Braking`, and `Swerving`. <br/><br/>Harsh Acceleration and Braking create medium(count2) to high(count3) gyro value alteration, Swerving create high(count3) gyro value alteration      |\n",
    "\n",
    "\n",
    "The aggregated data become input to Stacking algorithm consist of LogisticRegression, RandomForestClassifier, and GradientBoostingClassifier that maximize AUC. Class prediction probability cut off is set to 0.5 by default, this nummber could be set to create a balance between TP and FP.\n",
    "\n",
    "  \n",
    "</br>\n",
    "ps : Please put the test data and train data according to readme.md, then run all.\n",
    "\n",
    "</br>\n",
    "</br>\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "_* Cornering detection isn't implemented due to insufficient time to integrate bearing + gyro + time_  \n",
    "_** This notebook contain only algorithm and final procedure of my solution to detect dangerous driving. More detailed explanation of thought process, exploratory data analysis, and feature engineering  are in baseline(notebook|html) and advanced(notebook|html).**_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "\n",
    "## 2. Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurniawanekn/.local/lib/python3.5/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "#import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import pickle\n",
    "#import swifter\n",
    "import sys\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, roc_auc_score, roc_curve, auc, classification_report \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "\n",
    "from pystacknet.pystacknet import StackNetClassifier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell contain function to save object & load object\n",
    "\n",
    "Used to save file to disk after aggregation to save time.\n",
    "Will not be used in submission.\n",
    "\"\"\"\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open('/jet/prs/aiforsea/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open('/jet/prs/aiforsea/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statform(df_dict,booking_id,var):\n",
    "    \"\"\"\n",
    "    Generate statistical measurement of a variable with the same bookingID.\n",
    "    Use this in pandas apply.\n",
    "    \n",
    "    Input:\n",
    "    booking_id      bookingID\n",
    "    df_dict         list containing dataframe per bookingID\n",
    "    data df         label data\n",
    "    \"\"\"\n",
    "    booking_id = booking_id.bookingID\n",
    "    std = df_dict[booking_id][var].std()\n",
    "    maxx = df_dict[booking_id][var].max()\n",
    "    minn = df_dict[booking_id][var].min()\n",
    "    mean = df_dict[booking_id][var].mean()\n",
    "    med = df_dict[booking_id][var].median()\n",
    "    \n",
    "    return std, maxx, minn, mean, med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_statform(df_dict,data,booking_id,var):\n",
    "    \"\"\"\n",
    "    Generate statistical measurement of a variable with the same bookingID.\n",
    "    Use this in pandas apply.\n",
    "    \n",
    "    Input:\n",
    "    booking_id      bookingID\n",
    "    df_dict         list containing dataframe per bookingID\n",
    "    data df         label data\n",
    "    \"\"\"\n",
    "#     booking_id = booking_id.bookingID\n",
    "    var_series = df_dict[booking_id][var]\n",
    "    med = data.loc[data.bookingID == booking_id]['median_'+var].values[0]\n",
    "    mad = abs(var_series-med).mean()\n",
    "    \n",
    "    cnt = var_series.count()\n",
    "    \n",
    "    cut1 = 0\n",
    "    cut2 = 0\n",
    "    cut3 = 0\n",
    "## ver 4 gyro\n",
    "    if var=='gyro_x' or var=='gyro_y' or var=='gyro_z':\n",
    "        cut1 = len(np.where((abs(med-var_series)>(0.1)) & (abs(med-var_series)<=(0.2)))[0])\n",
    "        cut2 = len(np.where((abs(med-var_series)>(0.2)) & (abs(med-var_series)<=(0.4)))[0])\n",
    "        cut3 = len(np.where(abs(med-var_series)>(0.4))[0])\n",
    "    \n",
    "    if var=='acceleration_x' or var=='acceleration_y' or var=='acceleration_z':\n",
    "        cut1 = len(np.where((abs(med-var_series)>(1.0)) & (abs(med-var_series)<=(2.0)))[0])\n",
    "        cut2 = len(np.where((abs(med-var_series)>(2.0)) & (abs(med-var_series)<=(4.0)))[0])\n",
    "        cut3 = len(np.where(abs(med-var_series)>(4.0))[0])\n",
    "    \n",
    "#     return cut1,cut2,cut3,cut4,cut5\n",
    "    return mad,cut1,cut2,cut3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ediff(df_dict,booking_id,var):\n",
    "    #booking_id = booking_id.bookingID\n",
    "    var_series = df_dict[booking_id][var]\n",
    "    ediff = np.ediff1d(var_series)\n",
    "    return ediff.sum()/var_series.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "\n",
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"31\"></a>\n",
    "\n",
    "\n",
    "### 3.1 Load Data Train\n",
    "\n",
    "\n",
    "To speed things up, previously created training data pkl is loaded instead of calculating it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = load_obj('train_data')\n",
    "train_data_adv = load_obj('train_data_adv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookingID</th>\n",
       "      <th>label</th>\n",
       "      <th>std_acceleration_x</th>\n",
       "      <th>max_acceleration_x</th>\n",
       "      <th>min_acceleration_x</th>\n",
       "      <th>mean_acceleration_x</th>\n",
       "      <th>median_acceleration_x</th>\n",
       "      <th>std_acceleration_y</th>\n",
       "      <th>max_acceleration_y</th>\n",
       "      <th>min_acceleration_y</th>\n",
       "      <th>mean_acceleration_y</th>\n",
       "      <th>median_acceleration_y</th>\n",
       "      <th>std_acceleration_z</th>\n",
       "      <th>max_acceleration_z</th>\n",
       "      <th>min_acceleration_z</th>\n",
       "      <th>mean_acceleration_z</th>\n",
       "      <th>median_acceleration_z</th>\n",
       "      <th>std_gyro_x</th>\n",
       "      <th>max_gyro_x</th>\n",
       "      <th>min_gyro_x</th>\n",
       "      <th>mean_gyro_x</th>\n",
       "      <th>median_gyro_x</th>\n",
       "      <th>std_gyro_y</th>\n",
       "      <th>max_gyro_y</th>\n",
       "      <th>min_gyro_y</th>\n",
       "      <th>mean_gyro_y</th>\n",
       "      <th>median_gyro_y</th>\n",
       "      <th>std_gyro_z</th>\n",
       "      <th>max_gyro_z</th>\n",
       "      <th>min_gyro_z</th>\n",
       "      <th>mean_gyro_z</th>\n",
       "      <th>median_gyro_z</th>\n",
       "      <th>std_second</th>\n",
       "      <th>max_second</th>\n",
       "      <th>min_second</th>\n",
       "      <th>mean_second</th>\n",
       "      <th>median_second</th>\n",
       "      <th>std_Speed</th>\n",
       "      <th>max_Speed</th>\n",
       "      <th>min_Speed</th>\n",
       "      <th>mean_Speed</th>\n",
       "      <th>median_Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111669149733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.588776</td>\n",
       "      <td>2.614548</td>\n",
       "      <td>-2.825244</td>\n",
       "      <td>0.114490</td>\n",
       "      <td>0.193936</td>\n",
       "      <td>0.421854</td>\n",
       "      <td>14.674510</td>\n",
       "      <td>7.163670</td>\n",
       "      <td>9.770731</td>\n",
       "      <td>9.763853</td>\n",
       "      <td>0.731091</td>\n",
       "      <td>2.846793</td>\n",
       "      <td>-2.545114</td>\n",
       "      <td>0.037044</td>\n",
       "      <td>0.019154</td>\n",
       "      <td>0.023377</td>\n",
       "      <td>0.144156</td>\n",
       "      <td>-0.222364</td>\n",
       "      <td>-0.000616</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.072785</td>\n",
       "      <td>0.376463</td>\n",
       "      <td>-0.391394</td>\n",
       "      <td>0.010443</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.029111</td>\n",
       "      <td>0.149720</td>\n",
       "      <td>-0.202138</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>220.980774</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>382.0</td>\n",
       "      <td>5.683601</td>\n",
       "      <td>19.630571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.221818</td>\n",
       "      <td>3.448480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335007449205</td>\n",
       "      <td>1</td>\n",
       "      <td>1.107360</td>\n",
       "      <td>5.616969</td>\n",
       "      <td>-4.158855</td>\n",
       "      <td>0.232874</td>\n",
       "      <td>0.185556</td>\n",
       "      <td>0.596235</td>\n",
       "      <td>13.769474</td>\n",
       "      <td>6.890723</td>\n",
       "      <td>9.554995</td>\n",
       "      <td>9.535200</td>\n",
       "      <td>1.524342</td>\n",
       "      <td>8.121380</td>\n",
       "      <td>-8.851634</td>\n",
       "      <td>0.869236</td>\n",
       "      <td>0.869122</td>\n",
       "      <td>0.081049</td>\n",
       "      <td>0.415779</td>\n",
       "      <td>-1.319690</td>\n",
       "      <td>-0.001973</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>0.162387</td>\n",
       "      <td>1.639887</td>\n",
       "      <td>-0.684455</td>\n",
       "      <td>-0.005595</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>0.028351</td>\n",
       "      <td>0.168736</td>\n",
       "      <td>-0.327287</td>\n",
       "      <td>-0.002869</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>303.253204</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>524.500000</td>\n",
       "      <td>524.5</td>\n",
       "      <td>6.092663</td>\n",
       "      <td>19.367985</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.029686</td>\n",
       "      <td>3.767982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171798691856</td>\n",
       "      <td>0</td>\n",
       "      <td>0.588128</td>\n",
       "      <td>2.896984</td>\n",
       "      <td>-1.864485</td>\n",
       "      <td>0.279267</td>\n",
       "      <td>0.243610</td>\n",
       "      <td>0.713546</td>\n",
       "      <td>12.477382</td>\n",
       "      <td>5.531803</td>\n",
       "      <td>9.625053</td>\n",
       "      <td>9.657013</td>\n",
       "      <td>0.521369</td>\n",
       "      <td>3.323152</td>\n",
       "      <td>-1.467047</td>\n",
       "      <td>-0.041197</td>\n",
       "      <td>-0.092177</td>\n",
       "      <td>0.052078</td>\n",
       "      <td>0.296144</td>\n",
       "      <td>-0.261522</td>\n",
       "      <td>-0.009650</td>\n",
       "      <td>-0.010653</td>\n",
       "      <td>0.053446</td>\n",
       "      <td>0.280964</td>\n",
       "      <td>-0.294013</td>\n",
       "      <td>0.009246</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>0.045928</td>\n",
       "      <td>0.114782</td>\n",
       "      <td>-0.263653</td>\n",
       "      <td>-0.031219</td>\n",
       "      <td>-0.030626</td>\n",
       "      <td>133.898758</td>\n",
       "      <td>939.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>724.659546</td>\n",
       "      <td>728.0</td>\n",
       "      <td>7.782730</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>16.419031</td>\n",
       "      <td>20.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1520418422900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.837849</td>\n",
       "      <td>8.741074</td>\n",
       "      <td>-8.099609</td>\n",
       "      <td>-0.534042</td>\n",
       "      <td>-0.581360</td>\n",
       "      <td>0.639000</td>\n",
       "      <td>12.019928</td>\n",
       "      <td>4.228897</td>\n",
       "      <td>9.824681</td>\n",
       "      <td>9.885529</td>\n",
       "      <td>0.974887</td>\n",
       "      <td>8.839203</td>\n",
       "      <td>-7.429596</td>\n",
       "      <td>0.732369</td>\n",
       "      <td>0.629425</td>\n",
       "      <td>0.113392</td>\n",
       "      <td>2.479202</td>\n",
       "      <td>-1.469772</td>\n",
       "      <td>-0.001024</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>0.115673</td>\n",
       "      <td>0.891098</td>\n",
       "      <td>-1.458145</td>\n",
       "      <td>-0.008423</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>0.121698</td>\n",
       "      <td>2.198975</td>\n",
       "      <td>-1.821945</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>273.821014</td>\n",
       "      <td>944.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>471.481201</td>\n",
       "      <td>472.0</td>\n",
       "      <td>8.436861</td>\n",
       "      <td>24.850000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>13.459440</td>\n",
       "      <td>17.190001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>798863917116</td>\n",
       "      <td>0</td>\n",
       "      <td>1.558288</td>\n",
       "      <td>11.064803</td>\n",
       "      <td>-8.343793</td>\n",
       "      <td>0.133678</td>\n",
       "      <td>0.239420</td>\n",
       "      <td>0.855155</td>\n",
       "      <td>15.291766</td>\n",
       "      <td>5.301960</td>\n",
       "      <td>9.619421</td>\n",
       "      <td>9.625888</td>\n",
       "      <td>1.330740</td>\n",
       "      <td>6.452374</td>\n",
       "      <td>-4.419696</td>\n",
       "      <td>1.110142</td>\n",
       "      <td>1.138443</td>\n",
       "      <td>0.119730</td>\n",
       "      <td>0.761138</td>\n",
       "      <td>-0.768468</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.119985</td>\n",
       "      <td>0.535118</td>\n",
       "      <td>-0.378736</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.026289</td>\n",
       "      <td>0.095295</td>\n",
       "      <td>-0.117286</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>160.358978</td>\n",
       "      <td>554.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.000000</td>\n",
       "      <td>277.0</td>\n",
       "      <td>6.829455</td>\n",
       "      <td>21.993572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.729576</td>\n",
       "      <td>10.074869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bookingID  label  std_acceleration_x  max_acceleration_x  \\\n",
       "0   111669149733      0            0.588776            2.614548   \n",
       "1   335007449205      1            1.107360            5.616969   \n",
       "2   171798691856      0            0.588128            2.896984   \n",
       "3  1520418422900      0            0.837849            8.741074   \n",
       "4   798863917116      0            1.558288           11.064803   \n",
       "\n",
       "   min_acceleration_x  mean_acceleration_x  median_acceleration_x  \\\n",
       "0           -2.825244             0.114490               0.193936   \n",
       "1           -4.158855             0.232874               0.185556   \n",
       "2           -1.864485             0.279267               0.243610   \n",
       "3           -8.099609            -0.534042              -0.581360   \n",
       "4           -8.343793             0.133678               0.239420   \n",
       "\n",
       "   std_acceleration_y  max_acceleration_y  min_acceleration_y  \\\n",
       "0            0.421854           14.674510            7.163670   \n",
       "1            0.596235           13.769474            6.890723   \n",
       "2            0.713546           12.477382            5.531803   \n",
       "3            0.639000           12.019928            4.228897   \n",
       "4            0.855155           15.291766            5.301960   \n",
       "\n",
       "   mean_acceleration_y  median_acceleration_y  std_acceleration_z  \\\n",
       "0             9.770731               9.763853            0.731091   \n",
       "1             9.554995               9.535200            1.524342   \n",
       "2             9.625053               9.657013            0.521369   \n",
       "3             9.824681               9.885529            0.974887   \n",
       "4             9.619421               9.625888            1.330740   \n",
       "\n",
       "   max_acceleration_z  min_acceleration_z  mean_acceleration_z  \\\n",
       "0            2.846793           -2.545114             0.037044   \n",
       "1            8.121380           -8.851634             0.869236   \n",
       "2            3.323152           -1.467047            -0.041197   \n",
       "3            8.839203           -7.429596             0.732369   \n",
       "4            6.452374           -4.419696             1.110142   \n",
       "\n",
       "   median_acceleration_z  std_gyro_x  max_gyro_x  min_gyro_x  mean_gyro_x  \\\n",
       "0               0.019154    0.023377    0.144156   -0.222364    -0.000616   \n",
       "1               0.869122    0.081049    0.415779   -1.319690    -0.001973   \n",
       "2              -0.092177    0.052078    0.296144   -0.261522    -0.009650   \n",
       "3               0.629425    0.113392    2.479202   -1.469772    -0.001024   \n",
       "4               1.138443    0.119730    0.761138   -0.768468     0.002215   \n",
       "\n",
       "   median_gyro_x  std_gyro_y  max_gyro_y  min_gyro_y  mean_gyro_y  \\\n",
       "0      -0.000009    0.072785    0.376463   -0.391394     0.010443   \n",
       "1      -0.000831    0.162387    1.639887   -0.684455    -0.005595   \n",
       "2      -0.010653    0.053446    0.280964   -0.294013     0.009246   \n",
       "3      -0.000290    0.115673    0.891098   -1.458145    -0.008423   \n",
       "4       0.003665    0.119985    0.535118   -0.378736     0.007722   \n",
       "\n",
       "   median_gyro_y  std_gyro_z  max_gyro_z  min_gyro_z  mean_gyro_z  \\\n",
       "0       0.002003    0.029111    0.149720   -0.202138     0.001209   \n",
       "1      -0.000286    0.028351    0.168736   -0.327287    -0.002869   \n",
       "2       0.004794    0.045928    0.114782   -0.263653    -0.031219   \n",
       "3      -0.000229    0.121698    2.198975   -1.821945     0.000776   \n",
       "4       0.003665    0.026289    0.095295   -0.117286    -0.000900   \n",
       "\n",
       "   median_gyro_z  std_second  max_second  min_second  mean_second  \\\n",
       "0       0.000669  220.980774       764.0         0.0   382.000000   \n",
       "1      -0.000474  303.253204      1049.0         0.0   524.500000   \n",
       "2      -0.030626  133.898758       939.0         0.0   724.659546   \n",
       "3       0.000122  273.821014       944.0         0.0   471.481201   \n",
       "4       0.000000  160.358978       554.0         0.0   277.000000   \n",
       "\n",
       "   median_second  std_Speed  max_Speed  min_Speed  mean_Speed  median_Speed  \n",
       "0          382.0   5.683601  19.630571        0.0    5.221818      3.448480  \n",
       "1          524.5   6.092663  19.367985       -1.0    6.029686      3.767982  \n",
       "2          728.0   7.782730  26.500000       -1.0   16.419031     20.750000  \n",
       "3          472.0   8.436861  24.850000       -1.0   13.459440     17.190001  \n",
       "4          277.0   6.829455  21.993572        0.0    8.729576     10.074869  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookingID</th>\n",
       "      <th>label</th>\n",
       "      <th>mad_acceleration_x</th>\n",
       "      <th>count1_acceleration_x</th>\n",
       "      <th>count2_acceleration_x</th>\n",
       "      <th>count3_acceleration_x</th>\n",
       "      <th>mad_acceleration_y</th>\n",
       "      <th>count1_acceleration_y</th>\n",
       "      <th>count2_acceleration_y</th>\n",
       "      <th>count3_acceleration_y</th>\n",
       "      <th>mad_acceleration_z</th>\n",
       "      <th>count1_acceleration_z</th>\n",
       "      <th>count2_acceleration_z</th>\n",
       "      <th>count3_acceleration_z</th>\n",
       "      <th>mad_gyro_x</th>\n",
       "      <th>count1_gyro_x</th>\n",
       "      <th>count2_gyro_x</th>\n",
       "      <th>count3_gyro_x</th>\n",
       "      <th>mad_gyro_y</th>\n",
       "      <th>count1_gyro_y</th>\n",
       "      <th>count2_gyro_y</th>\n",
       "      <th>count3_gyro_y</th>\n",
       "      <th>mad_gyro_z</th>\n",
       "      <th>count1_gyro_z</th>\n",
       "      <th>count2_gyro_z</th>\n",
       "      <th>count3_gyro_z</th>\n",
       "      <th>speed_diff</th>\n",
       "      <th>mounted</th>\n",
       "      <th>trip_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111669149733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.405293</td>\n",
       "      <td>45.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.240010</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.498535</td>\n",
       "      <td>119.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.012004</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038068</td>\n",
       "      <td>53.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017345</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004127</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335007449205</td>\n",
       "      <td>1</td>\n",
       "      <td>0.794799</td>\n",
       "      <td>183.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.388205</td>\n",
       "      <td>95.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.997966</td>\n",
       "      <td>240.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.042690</td>\n",
       "      <td>68.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.097751</td>\n",
       "      <td>176.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.017706</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002071</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171798691856</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431753</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501752</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.371503</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036484</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036529</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033170</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1520418422900</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503159</td>\n",
       "      <td>89.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.374170</td>\n",
       "      <td>33.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.551717</td>\n",
       "      <td>94.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.021656</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.047943</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.024179</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.018485</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>798863917116</td>\n",
       "      <td>0</td>\n",
       "      <td>1.007355</td>\n",
       "      <td>109.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.509378</td>\n",
       "      <td>64.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.950522</td>\n",
       "      <td>120.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.074825</td>\n",
       "      <td>99.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.078259</td>\n",
       "      <td>101.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.018234</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bookingID  label  mad_acceleration_x  count1_acceleration_x  \\\n",
       "0   111669149733      0            0.405293                   45.0   \n",
       "1   335007449205      1            0.794799                  183.0   \n",
       "2   171798691856      0            0.431753                   32.0   \n",
       "3  1520418422900      0            0.503159                   89.0   \n",
       "4   798863917116      0            1.007355                  109.0   \n",
       "\n",
       "   count2_acceleration_x  count3_acceleration_x  mad_acceleration_y  \\\n",
       "0                   14.0                    0.0            0.240010   \n",
       "1                   82.0                    5.0            0.388205   \n",
       "2                    2.0                    0.0            0.501752   \n",
       "3                   26.0                    3.0            0.374170   \n",
       "4                   72.0                   16.0            0.509378   \n",
       "\n",
       "   count1_acceleration_y  count2_acceleration_y  count3_acceleration_y  \\\n",
       "0                   13.0                    4.0                    1.0   \n",
       "1                   95.0                    9.0                    1.0   \n",
       "2                   45.0                    7.0                    1.0   \n",
       "3                   33.0                   11.0                    4.0   \n",
       "4                   64.0                   21.0                    2.0   \n",
       "\n",
       "   mad_acceleration_z  count1_acceleration_z  count2_acceleration_z  \\\n",
       "0            0.498535                  119.0                   15.0   \n",
       "1            0.997966                  240.0                  111.0   \n",
       "2            0.371503                   20.0                    2.0   \n",
       "3            0.551717                   94.0                   12.0   \n",
       "4            0.950522                  120.0                   69.0   \n",
       "\n",
       "   count3_acceleration_z  mad_gyro_x  count1_gyro_x  count2_gyro_x  \\\n",
       "0                    0.0    0.012004            4.0            2.0   \n",
       "1                   26.0    0.042690           68.0           25.0   \n",
       "2                    0.0    0.036484           18.0            4.0   \n",
       "3                   13.0    0.021656            4.0            6.0   \n",
       "4                    6.0    0.074825           99.0           41.0   \n",
       "\n",
       "   count3_gyro_x  mad_gyro_y  count1_gyro_y  count2_gyro_y  count3_gyro_y  \\\n",
       "0            0.0    0.038068           53.0           29.0            0.0   \n",
       "1            4.0    0.097751          176.0          119.0           43.0   \n",
       "2            0.0    0.036529           24.0            2.0            0.0   \n",
       "3            7.0    0.047943           54.0           51.0           12.0   \n",
       "4            6.0    0.078259          101.0           60.0            3.0   \n",
       "\n",
       "   mad_gyro_z  count1_gyro_z  count2_gyro_z  count3_gyro_z  speed_diff  \\\n",
       "0    0.017345           10.0            1.0            0.0   -0.004127   \n",
       "1    0.017706            5.0            1.0            0.0   -0.002071   \n",
       "2    0.033170           16.0            1.0            0.0    0.002364   \n",
       "3    0.024179            4.0            2.0           10.0    0.018485   \n",
       "4    0.018234            3.0            0.0            0.0    0.011250   \n",
       "\n",
       "   mounted  trip_duration  \n",
       "0        1              2  \n",
       "1        1              3  \n",
       "2        1              3  \n",
       "3        1              3  \n",
       "4        1              1  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_adv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"32\"></a>\n",
    "\n",
    "\n",
    "### 3.2 Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.merge(train_data, train_data_adv, on=['bookingID','label'])\n",
    "X = X.drop('label', axis=1)\n",
    "\n",
    "# drop column that didn't make any sense\n",
    "X.drop('bookingID', axis=1, inplace=True)\n",
    "X.drop(['median_second','mean_second','std_second','min_second'], axis=1, inplace=True) # no meaning, represented by max second\n",
    "X.drop(['min_Speed'], axis=1, inplace=True) # all 0 \n",
    "X.drop(['trip_duration'], axis=1, inplace=True) # max_second better\n",
    "\n",
    "Y = train_data_adv['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col = X.columns.tolist() # for data test columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Start of Level 0 ======================\n",
      "Input Dimensionality 61 at Level 0 \n",
      "4 models included in Level 0 \n",
      "Fold 1/4 , model 0 , auc===0.693837 \n",
      "Fold 1/4 , model 1 , auc===0.710841 \n",
      "Fold 1/4 , model 2 , auc===0.717507 \n",
      "Fold 1/4 , model 3 , auc===0.716961 \n",
      "=========== end of fold 1 in level 0 ===========\n",
      "Fold 2/4 , model 0 , auc===0.690396 \n",
      "Fold 2/4 , model 1 , auc===0.714664 \n",
      "Fold 2/4 , model 2 , auc===0.718058 \n",
      "Fold 2/4 , model 3 , auc===0.717392 \n",
      "=========== end of fold 2 in level 0 ===========\n",
      "Fold 3/4 , model 0 , auc===0.709514 \n",
      "Fold 3/4 , model 1 , auc===0.728336 \n",
      "Fold 3/4 , model 2 , auc===0.724586 \n",
      "Fold 3/4 , model 3 , auc===0.723911 \n",
      "=========== end of fold 3 in level 0 ===========\n",
      "Fold 4/4 , model 0 , auc===0.705526 \n",
      "Fold 4/4 , model 1 , auc===0.733591 \n",
      "Fold 4/4 , model 2 , auc===0.731622 \n",
      "Fold 4/4 , model 3 , auc===0.732037 \n",
      "=========== end of fold 4 in level 0 ===========\n",
      "Level 0, model 0 , auc===0.699819 \n",
      "Level 0, model 1 , auc===0.721858 \n",
      "Level 0, model 2 , auc===0.722943 \n",
      "Level 0, model 3 , auc===0.722575 \n",
      "Output dimensionality of level 0 is 4 \n",
      "====================== End of Level 0 ======================\n",
      " level 0 lasted 166.727864 seconds \n",
      "====================== Start of Level 1 ======================\n",
      "Input Dimensionality 4 at Level 1 \n",
      "1 models included in Level 1 \n",
      "Fold 1/4 , model 0 , auc===0.721726 \n",
      "=========== end of fold 1 in level 1 ===========\n",
      "Fold 2/4 , model 0 , auc===0.722509 \n",
      "=========== end of fold 2 in level 1 ===========\n",
      "Fold 3/4 , model 0 , auc===0.733509 \n",
      "=========== end of fold 3 in level 1 ===========\n",
      "Fold 4/4 , model 0 , auc===0.740170 \n",
      "=========== end of fold 4 in level 1 ===========\n",
      "Level 1, model 0 , auc===0.729478 \n",
      "Output dimensionality of level 1 is 1 \n",
      "====================== End of Level 1 ======================\n",
      " level 1 lasted 0.153106 seconds \n",
      "====================== End of fit ======================\n",
      " fit() lasted 166.894297 seconds \n"
     ]
    }
   ],
   "source": [
    "models=[\n",
    "        ######## First level ########\n",
    "        [RandomForestClassifier (n_estimators=100, max_depth=5, max_features='auto', random_state=1),\n",
    "        GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, max_features='auto', random_state=1),\n",
    "        #DecisionTreeClassifier(),\n",
    "        LogisticRegression(random_state=1, solver='liblinear',class_weight='balanced'),\n",
    "        LogisticRegression(random_state=1, solver='liblinear'),\n",
    "        ],\n",
    "        ######## Second level ########\n",
    "        [LogisticRegression(random_state=1, solver='liblinear')]\n",
    "        ]\n",
    "\n",
    "model=StackNetClassifier(models, metric=\"auc\", folds=4,\n",
    "    restacking=False,use_retraining=True, use_proba=True, \n",
    "    random_state=12345,n_jobs=1, verbose=1)\n",
    "\n",
    "\n",
    "# BACKUP just in case your pystacknet couldn't be installed properly, use logistic regression\n",
    "# surprisingly, logistic regression with balanced strategy works best in validation\n",
    "\n",
    "#model = LogisticRegression(random_state=1, solver='liblinear', class_weight='balanced'),\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X,Y)\n",
    "# model = RandomForestClassifier() # Backup just in case your pystacknet couldn't be installed properly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "\n",
    "\n",
    "## 4. Predict Data Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"41\"></a>\n",
    "\n",
    "\n",
    "### 4.1 Create Data Test Feature\n",
    "Please change according to data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.6 s, sys: 3.3 s, total: 31.9 s\n",
      "Wall time: 31.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Change to TEST label file\n",
    "test_data = pd.read_csv(glob.glob(\"test/labels/*.csv\")[0])\n",
    "\n",
    "\n",
    "# TEST feature file\n",
    "test_files = glob.glob(\"test/features/*.csv\")\n",
    "test_features = [pd.read_csv(f) for f in test_files]\n",
    "test_all_features = pd.concat(test_features,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.2 s, sys: 3.34 s, total: 23.6 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# change dtype for a bit of efficientcy\n",
    "test_all_features = test_all_features.astype({\n",
    "    'bookingID': 'int64', \n",
    "    'Accuracy':'float32',\n",
    "    'Bearing':'float32',\n",
    "    'acceleration_x':'float32',\n",
    "    'acceleration_y':'float32',\n",
    "    'acceleration_z':'float32',\n",
    "    'gyro_x':'float32',\n",
    "    'gyro_y':'float32',\n",
    "    'gyro_z':'float32',\n",
    "    'second':'float32',\n",
    "    'Speed':'float32'\n",
    "})\n",
    "\n",
    "test_all_features.sort_values(['bookingID','second'], inplace=True) # sort here first for efficiency in the next process\n",
    "test_all_features.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 20s, sys: 784 ms, total: 8min 20s\n",
      "Wall time: 8min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df_dict = {}\n",
    "\n",
    "for booking_id in test_data['bookingID']:\n",
    "\n",
    "    #df_dict[booking_id] = all_features.loc[all_features.bookingID==booking_id]\n",
    "    test_df_dict[booking_id] = copy.deepcopy(test_all_features.loc[test_all_features.bookingID==booking_id])\n",
    "    #df_dict[booking_id] = all_features.query('bookingID == @booking_id')\n",
    "    \n",
    "test_df_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 47s, sys: 1.14 s, total: 2min 48s\n",
      "Wall time: 2min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# BASELINE FEATURE\n",
    "\n",
    "\n",
    "cols = ['acceleration_x', 'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z', 'second', 'Speed'] \n",
    "\n",
    "for col in cols:\n",
    "    std_str = 'std_' + col\n",
    "    max_str = 'max_' + col\n",
    "    min_str = 'min_' + col\n",
    "    mean_str = 'mean_' + col\n",
    "    med_str = 'median_' + col\n",
    "    \n",
    "    test_data[[std_str, max_str, min_str, mean_str, med_str]] = test_data.apply(lambda x:statform(test_df_dict,x,col), axis = 1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 35s, sys: 136 ms, total: 10min 35s\n",
      "Wall time: 10min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "# ADVANCED FEATURE\n",
    "\n",
    "\n",
    "# High & Low Pass Filter count\n",
    "\n",
    "\n",
    "test_data_adv = test_data[['bookingID','label']].copy()\n",
    "\n",
    "cols = ['acceleration_x', 'acceleration_y', 'acceleration_z', 'gyro_x', 'gyro_y', 'gyro_z'] \n",
    "\n",
    "for col in cols:\n",
    "    mad = 'mad_' + col\n",
    "    cut1 = 'count1_' + col\n",
    "    cut2 = 'count2_' + col\n",
    "    cut3 = 'count3_' + col\n",
    "    \n",
    "    test_data_adv[[mad,cut1, cut2, cut3]] = test_data_adv.apply(lambda x:adv_statform(test_df_dict,test_data,x['bookingID'],col), axis = 1, result_type='expand')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_adv['speed_diff'] = test_data_adv.apply(lambda x:ediff(test_df_dict,x['bookingID'],'Speed'), axis=1)\n",
    "test_data_adv['mounted'] = np.where((test_data['median_acceleration_y']>7) & (test_data['median_acceleration_y']<13), 1, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"42\"></a>\n",
    "\n",
    "\n",
    "### 4.2 Predict Probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================== Start of Level 0 ======================\n",
      "1 estimators included in Level 0 \n",
      "====================== Start of Level 1 ======================\n",
      "1 estimators included in Level 1 \n",
      "====================== Start of Level 0 ======================\n",
      "1 estimators included in Level 0 \n",
      "====================== Start of Level 1 ======================\n",
      "1 estimators included in Level 1 \n"
     ]
    }
   ],
   "source": [
    "X_test = pd.concat([test_data, test_data_adv], axis=1)[list_col]\n",
    "\n",
    "preds=model.predict_proba(X_test)\n",
    "preds_train=model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"43\"></a>\n",
    "\n",
    "\n",
    "### 4.3 Predict Label with Probability Cut Off \n",
    "\n",
    "We're using default 0.5 because it gives pretty good recall(1) while not getting too many false positives.\n",
    "This cut off threshold should be adjusted according to preferred risk appetite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "AUC score : 0.79593427\n",
      "Confusion Matrix : \n",
      " [[14661   340]\n",
      " [ 3534  1459]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.88     15001\n",
      "           1       0.81      0.29      0.43      4993\n",
      "\n",
      "    accuracy                           0.81     19994\n",
      "   macro avg       0.81      0.63      0.66     19994\n",
      "weighted avg       0.81      0.81      0.77     19994\n",
      "\n",
      "\n",
      "Train Predict distribution\n",
      " 0    0.909232\n",
      "1    0.090768\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Test Predict distribution\n",
      " 0    0.909232\n",
      "1    0.090768\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "t = 0.5 # default 0.5\n",
    "t1 = 1 - t\n",
    "pred = pd.DataFrame({'pred0':preds[:,0],'pred1':preds[:,1]})\n",
    "pred['pred'] = np.where(pred['pred0']<=t1, '1', '0').astype(int)\n",
    "\n",
    "pred_train = pd.DataFrame({'pred0':preds_train[:,0],'pred1':preds_train[:,1]})\n",
    "pred_train['pred'] = np.where(pred_train['pred0']<=t1, '1', '0').astype(int)\n",
    "\n",
    "print (\"TRAIN\")\n",
    "print (\"AUC score : %.8f\" % roc_auc_score(Y, preds_train[:,1]))\n",
    "print (\"Confusion Matrix : \\n\", confusion_matrix(Y, pred_train.pred.values))\n",
    "print(classification_report(Y, pred_train.pred.values))\n",
    "print(\"\\nTrain Predict distribution\\n\",pd.Series(pred.pred.values).value_counts(normalize=True))\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\\nTest Predict distribution\\n\",pd.Series(pred.pred.values).value_counts(normalize=True)) # same distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "\n",
    "\n",
    "## 5. Save Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"51\"></a>\n",
    "\n",
    "### 5.1 Into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bookingID</th>\n",
       "      <th>probability</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111669149733</td>\n",
       "      <td>0.160750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335007449205</td>\n",
       "      <td>0.301708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>171798691856</td>\n",
       "      <td>0.095123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1520418422900</td>\n",
       "      <td>0.135474</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>798863917116</td>\n",
       "      <td>0.182035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bookingID  probability  class\n",
       "0   111669149733     0.160750      0\n",
       "1   335007449205     0.301708      0\n",
       "2   171798691856     0.095123      0\n",
       "3  1520418422900     0.135474      0\n",
       "4   798863917116     0.182035      0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_file = pd.DataFrame({'bookingID':test_data.bookingID,'probability':preds[:,1]})\n",
    "pred_file['class'] = np.where(pred['pred0']<=t1, '1', '0').astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20018"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_file['probability'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18201\n",
       "1     1817\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_file['class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"52\"></a>\n",
    "\n",
    "\n",
    "### 5.2 Into CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_file.to_csv('pred.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
